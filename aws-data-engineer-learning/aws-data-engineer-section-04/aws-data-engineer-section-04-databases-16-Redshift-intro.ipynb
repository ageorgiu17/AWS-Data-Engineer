{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Redshift reprezintă serviciul din AWS pentru un Data Wearhouse distribuit care se poate scala până la Pentabytes de date. Acest Data Wearhouse este manageriat în totalitate de către Amazon, asta înseamnă că partea de mentenență la clustere este realizată în totalitate de către Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redshit este:\n",
    "\n",
    "- Un Data Warehouse rapid, manageriat în totalitate de către AWS care se poate scala la pentabytes de date\n",
    "\n",
    "- Performanță de 10x mai bună decât alte Data Wearhouse. Ajunge la aceste performanțe utilizând Machine Learning, massive parallel query execution și stocare de date pe coloane, nu pe rânduri.\n",
    "\n",
    "- a fost creat pentru OLAD (Online Analytic Processing). Din acest motiv, atunci când realizăm anumite query-uri pe acest Data Wearhouse nu ar trebui să ne așteptăm la răspunsuri super rapide.\n",
    "\n",
    "- pentru partea de cost, pentru acest data wearhouse se plătește ceea ce se folosește, nu trebuie să plătim ceva înainte\n",
    "\n",
    "- se poate face scale-up sau scale-down la acest tip de Data Wearhouse destul de ușor\n",
    "\n",
    "- replicare de date și backup create automat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cazuri în care este folosit Redshift\n",
    "\n",
    "- accelerarea workload-urilor ce țin de partea de analitică/analiză\n",
    "\n",
    "- unificarea dintre Data Wearhouse și Data Lake \n",
    "\n",
    "- modernizarea de Data Wearhouse \n",
    "\n",
    "- analiză globală de vânzări\n",
    "\n",
    "- stocarea de date istorice pentru stock-uri\n",
    "\n",
    "- analiza de click-uri și impresii pentru reclame\n",
    "\n",
    "- agregarea de date din gaiming\n",
    "\n",
    "- analiza de trend-uri sociale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arhitectura din Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../ss/aws-data-engineer-section-04/section-04-ss-34.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obiectul de bază din Redshit este un cluster. Acest cluster este creat dintr-un \"Leader Node\" și alți \"Compute Node\". În funcție de tipul de Node, putem să avem de la 1 până la 128 de Compute Nodes într-un Cluster de Redshift. Fiecare cluster de Redshift poate să conțină una sau mai multe baze de date.\n",
    "\n",
    "Rolul pe care îl are acel Leader Node este de a crea comunicarea dintre aplicația client și datele din acel Data Wearhouse. Datele respectivă o să fie stocate în Compute Nodes. Acest Leader Node primește toate query-urile din partea aplicației, parsează aceste query-uri și crează planuri de execuție (pași ordinați care trebuie realizați pentru a rula acele query-uri) după care coordonează execuția în paralel a acelor planuri de execuție cu Compute Nodes și aggregează rezultatele intermediare de la acele Compute Nodes. La final, acest Leader Node o să trimită rezultatele către aplicația client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Nodes sunt responsabili de a rula acele planuri de execuție pe care îi primește de la Leader Node și transmit date între ei pentru a putea duce la bun sfârșit aceste planuri de execuție (pentru a rula acele query-uri). Fiecare compute Node are CPU, GPU, memorie dedicate și spațiu de disc atașat, acestea fiind determinate de tipul de node pe care îl alegem atunci când creem un cluster de Redshift. Atunci când creem un cluster de Redshift putem să alegem din două categorii de nodes:\n",
    "\n",
    "- Dense Storage (DS)\n",
    "\n",
    "    Acest tip de node ne permite să creem un Data Wearhouse extrem de mare folosind memorie de tipul HDD (memorie care este mai ieftină). Acestea sunt disponibile în două mărimi (extra large și 8 XL)\n",
    "\n",
    "- Dense Compute (DC)\n",
    "\n",
    "    Acest tip de node ne permită să creem un Data Wearhouse performant (la un cost mai mare) folosind memorie rapidă de CPU, mulți RAM și stocare SSD. Există de asemenea două mărimi (large și 8 XL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul unui Compute Node, există Node Slices. Fiecare Compute Node este divizat în Compute Slices iar o porțiune din caracteristicile nodului (CPU, RAM, memorie) o să fie alocate pentru fiecare slice individual, iar acest slice se ocupă de partea de procesare care este atribuită node-ului respectiv. Acest număr de slices este determinat de mărimea Compute Node-ului din Cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
